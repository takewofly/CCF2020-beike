{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_f1(y_true, y_pred):\n",
    "    print(\"origin:\",f1_score(y_true, y_pred>0.5))\n",
    "    best = 0\n",
    "    best_t = 0\n",
    "    for i in range(300,600,1):\n",
    "        tres = i / 1000\n",
    "        y_pred_bin =  (y_pred > tres).astype(int)\n",
    "        score = f1_score(y_true, y_pred_bin)\n",
    "        if score > best:\n",
    "            best = score\n",
    "            best_t = tres\n",
    "    print('best', best)\n",
    "    print('thres', best_t)\n",
    "    return best, best_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"./data/\"\n",
    "os.listdir(path+\"test/\")\n",
    "\n",
    "\n",
    "train_query = pd.read_table(path+\"train/train.query.tsv\",names=['qid','query'])\n",
    "train_reply = pd.read_table(path+\"train/train.reply.tsv\",names=[\"qid\",'rid','reply','label'])\n",
    "\n",
    "test_query = pd.read_table(path+\"test/test.query.tsv\",names=['qid','query'],encoding=\"gbk\")\n",
    "test_reply = pd.read_table(path+\"test/test.reply.tsv\",names=[\"qid\",'rid','reply'],encoding=\"gbk\")\n",
    "\n",
    "train=pd.merge(train_query,train_reply,on=\"qid\",how=\"left\")\n",
    "test=pd.merge(test_query,test_reply,on=\"qid\",how=\"left\")\n",
    "\n",
    "train=train[train['reply'].notnull()]\n",
    "\n",
    "train.index=range(len(train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['q_len']=train['query'].map(len)\n",
    "# train['r_len']=train['reply'].map(len)\n",
    "# train['text']=train['query']+\"_\"+train['reply']\n",
    "# train['text_len']=train['text'].map(len)\n",
    "\n",
    "# test['q_len']=test['query'].map(len)\n",
    "# test['r_len']=test['reply'].map(len)\n",
    "# test['text']=test['query']+\"_\"+test['reply']\n",
    "# test['text_len']=test['text'].map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train,test],ignore_index=True)\n",
    "train['id_count']=train['qid'].map(train['qid'].value_counts())\n",
    "test['id_count']=test['qid'].map(test['qid'].value_counts())\n",
    "\n",
    "train['query_count']=train['query'].map(data['query'].value_counts())\n",
    "test['query_count']=test['query'].map(data['query'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof1 = pd.read_csv(\"./oof/bert_base_oof_v2.csv\")\n",
    "oof1 = pd.read_csv(\"./oof/nezha_large_oof_v5.csv\")\n",
    "oof2 = pd.read_csv(\"./oof/roberta_large_oof.csv\")\n",
    "oof3 = pd.read_csv(\"./oof/nezha_large_oof.csv\")\n",
    "oof4 = pd.read_csv(\"./oof/bert_base_oof_v6.csv\")\n",
    "oof5 = pd.read_csv(\"./oof/macbert_oof_v6.csv\")\n",
    "oof6 = pd.read_csv(\"./oof/macbert_oof.csv\")\n",
    "oof7 = pd.read_csv(\"./oof/electra_large_oof.csv\")\n",
    "oof8 = pd.read_csv(\"./oof/bert_base_oof_v5.csv\")\n",
    "oof9 = pd.read_csv('./oof/exper_context_34_train_proba.csv', sep='\\t', names=['id', 'id_sub', 'query_context', 'reply', 'oof', 'label'])\n",
    "oof10 = pd.read_csv(\"./oof/nezha_large_oof_v6.csv\")\n",
    "oof11 = pd.read_csv('./oof/exper33_train_proba.csv', sep='\\t', names=['id', 'id_sub', 'query_context', 'reply', 'oof', 'label'])\n",
    "oof12 = pd.read_csv(\"./oof/nezha_large_oof_v7.csv\")\n",
    "oof13 = pd.read_csv('./oof/exper_context_35_train_proba.csv', sep='\\t', names=['id', 'id_sub', 'query_context', 'reply', 'oof', 'label'])\n",
    "oof14 = pd.read_csv(\"./oof/electra_large_oof_v6.csv\")\n",
    "oof15 = pd.read_csv('./oof/epxer_context_36_train_proba.csv', sep='\\t', names=['id', 'id_sub', 'query_context', 'reply', 'oof', 'label'])\n",
    "oof16 = pd.read_csv(\"./oof/bert_base_oof_v2.csv\")\n",
    "oof17 = pd.read_csv(\"./oof/nezha_large_oof_v8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof9 = oof9.sort_values(by=[\"id\",\"id_sub\"])\n",
    "oof11 = oof11.sort_values(by=[\"id\",\"id_sub\"])\n",
    "oof13 = oof13.sort_values(by=[\"id\",\"id_sub\"])\n",
    "oof15 = oof15.sort_values(by=[\"id\",\"id_sub\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof9.index=range(len(oof9))\n",
    "oof11.index=range(len(oof11))\n",
    "oof13.index=range(len(oof13))\n",
    "oof15.index=range(len(oof15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof9=oof9.drop([2194],0)\n",
    "oof11=oof11.drop([2194],0)\n",
    "oof13=oof13.drop([2194],0)\n",
    "oof15=oof15.drop([2194],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof9.index=range(len(oof9))\n",
    "oof11.index=range(len(oof11))\n",
    "oof13.index=range(len(oof13))\n",
    "oof15.index=range(len(oof15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['oof1']= oof1['pred1']\n",
    "train['oof2']= oof2['pred1']\n",
    "train['oof3']= oof3['pred1']\n",
    "train['oof4']= oof4['pred1']\n",
    "train['oof5']= oof5['pred1']\n",
    "train['oof6']= oof6['pred1']\n",
    "train['oof7']= oof7['pred1']\n",
    "train['oof8']= oof8['pred1']\n",
    "# train['oof9']= oof9['oof']\n",
    "train['oof10']= oof10['pred1']\n",
    "train['oof11']= oof11['oof']\n",
    "train['oof12']= oof12['pred1']\n",
    "train['oof13']= oof13['oof']\n",
    "train['oof14']= oof14['pred1']\n",
    "# train['oof15']= oof15['oof']\n",
    "# train['oof16']= oof16['pred1']\n",
    "train['oof17']= oof17['pred1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['oof9'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b67a0ecd3b6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"oof\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;31m# we skip the warning on Categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['oof9'] not in index\""
     ]
    }
   ],
   "source": [
    "train[[\"oof\"+str(i+1) for i in list(range(14))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['oof9'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a9d7aecd1d7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"oof\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;31m# we skip the warning on Categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['oof9'] not in index\""
     ]
    }
   ],
   "source": [
    "train[[\"oof\"+str(i+1) for i in list(range(14))+[16]]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21584, 6), (21584, 5), (21584, 6), (21584, 5))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof9.shape,oof10.shape,oof11.shape,oof12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof1.shape,oof2.shape,oof3.shape,oof4.shape,oof5.shape,oof6.shape,oof7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.read_csv(\"./submit/submit_nezha_large_pred_v5.csv\")\n",
    "sub2 = pd.read_csv(\"./submit/submit_roberta_large_pred.csv\")\n",
    "sub3 = pd.read_csv(\"./submit/submit_nezha_large_pred.csv\")\n",
    "sub4 = pd.read_csv(\"./submit/submit_bert_base_pred_v6.csv\")\n",
    "sub5 = pd.read_csv(\"./submit/submit_macbert_pred_v6.csv\")\n",
    "sub6 = pd.read_csv(\"./submit/submit_macbert_pred.csv\")\n",
    "sub7 = pd.read_csv(\"./submit/submit_electra_large_pred.csv\")\n",
    "sub8 = pd.read_csv(\"./submit/submit_bert_base_pred_v5.csv\")\n",
    "sub9 =  pd.read_csv('./oof/exper_context_34_test_proba.csv', sep='\\t', names=['id', 'id_sub', 'query_context', 'reply', 'proba'])\n",
    "\n",
    "sub10 = pd.read_csv(\"./submit/submit_nezha_large_pred_v6.csv\")\n",
    "sub11 =  pd.read_csv('./oof/exper33_test_proba.csv', sep='\\t', names=['id', 'id_sub', 'query_context', 'reply', 'proba'])\n",
    "sub12 = pd.read_csv(\"./submit/submit_nezha_large_pred_v7.csv\")\n",
    "sub13 =  pd.read_csv('./oof/exper_context_35_test_proba.csv', sep='\\t', names=['id', 'id_sub', 'query_context', 'reply', 'proba'])\n",
    "sub14 = pd.read_csv(\"./submit/submit_electra_large_pred_v6.csv\")\n",
    "sub15 =  pd.read_csv('./oof/exper_context_36_test_proba.csv', sep='\\t', names=['id', 'id_sub', 'query_context', 'reply', 'proba'])\n",
    "sub16 = pd.read_csv(\"./submit/submit_bert_base_pred_v2.csv\")\n",
    "sub17 = pd.read_csv(\"./submit/submit_nezha_large_pred_v8.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub9 = sub9.sort_values(by=[\"id\",\"id_sub\"])\n",
    "sub11 = sub11.sort_values(by=[\"id\",\"id_sub\"])\n",
    "sub13 = sub13.sort_values(by=[\"id\",\"id_sub\"])\n",
    "sub15 = sub15.sort_values(by=[\"id\",\"id_sub\"])\n",
    "sub9.index=range(len(sub9))\n",
    "sub11.index=range(len(sub11))\n",
    "sub13.index=range(len(sub13))\n",
    "sub15.index=range(len(sub15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['oof1']= sub1['pred']\n",
    "test['oof2']= sub2['pred']\n",
    "test['oof3']= sub3['pred']\n",
    "test['oof4']= sub4['pred']\n",
    "test['oof5']= sub5['pred']\n",
    "test['oof6']= sub6['pred']\n",
    "test['oof7']= sub7['pred']\n",
    "test['oof8']= sub8['pred']\n",
    "# test['oof9']= sub9['proba']\n",
    "test['oof10']= sub10['pred']\n",
    "test['oof11']= sub11['proba']\n",
    "test['oof12']= sub12['pred']\n",
    "test['oof13']= sub13['proba']\n",
    "test['oof14']= sub14['pred']\n",
    "# test['oof15']= sub15['proba']\n",
    "# test['oof16']= sub16['pred']\n",
    "test['oof17']= sub17['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['oof9'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-57887f3e478f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"oof\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;31m# we skip the warning on Categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['oof9'] not in index\""
     ]
    }
   ],
   "source": [
    "test[[\"oof\"+str(i+1) for i in list(range(14))]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['blend'] = (train['oof1']+train['oof2']+train['oof3']+train['oof6']+train['oof7']+train['oof8'])/6\n",
    "\n",
    "# test['blend'] = (test['oof1']+test['oof2']+test['oof3']+test['oof6']+test['oof7']+test['oof8'])/6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature(df_sub,col=\"oof3\"):\n",
    "    df_sub[\"rank_\"+col] = df_sub.groupby('qid')['rid'].rank(ascending=True).astype(int)\n",
    "    df_sub[\"rank_inv_\"+col] = df_sub.groupby('qid')['rid'].rank(ascending=False).astype(int)\n",
    "    df_sub_grouped = df_sub.groupby('qid')[\"rank_\"+col].count() #.agg({'Label':'max'})\n",
    "    df_sub_grouped = df_sub_grouped.to_frame(\"rank_max_\"+col).reset_index()\n",
    "    df_sub = pd.merge(df_sub, df_sub_grouped, how='left', on='qid')\n",
    "    \n",
    "    \n",
    "    def list_std(x):\n",
    "        return np.std(x[x>0])\n",
    "    \n",
    "    # Features\n",
    "    key_cols = [\"qid\"]\n",
    "    df_sub['p']=df_sub[col]\n",
    "    df_sub['p1_'+col] = df_sub.groupby(key_cols)['p'].apply(lambda x: x.shift().expanding().mean())\n",
    "    df_sub['diff_mean_'+col] = df_sub.groupby(key_cols)['p'].apply(lambda x: x.diff().expanding().mean())\n",
    "    df_sub['diff_std_'+col] = df_sub.groupby(key_cols)['p'].apply(lambda x: x.diff().expanding().std())\n",
    "    df_sub['p1_std_'+col] = df_sub.groupby(key_cols)['p'].apply(lambda x: x.shift().expanding().std())\n",
    "#     df_sub['p1_skew'] = df_sub.groupby(key_cols)['p'].apply(lambda x: x.shift().expanding().skew())\n",
    "    df_sub['p1_list_std'] = df_sub.groupby(key_cols)['p'].apply(lambda x:x.shift().expanding().apply(lambda x: list_std(x), raw=False))\n",
    "\n",
    "    df_sub['p1_inv_'+col] = df_sub.sort_values(key_cols + [\"rank_inv_\"+col]).groupby(key_cols)['p'].apply(lambda x: x.shift().expanding().mean())\n",
    "    df_sub['p1_inv_std_'+col] = df_sub.sort_values(key_cols + [\"rank_inv_\"+col]).groupby(key_cols)['p'].apply(lambda x: x.shift().expanding().std())\n",
    "#     df_sub['p1_inv_skew'] = df_sub.sort_values(key_cols + [\"rank_inv\"]).groupby(key_cols)['p'].apply(lambda x: x.shift().expanding().skew())\n",
    "    df_sub['p1_inv_list_std'] = df_sub.sort_values(key_cols + [\"rank_inv_\"+col]).groupby(key_cols)['p'].apply(lambda x: x.shift().expanding().apply(lambda x: list_std(x), raw=False))\n",
    "\n",
    "    df_sub[\"rank_perc_\"+col] = df_sub[\"rank_\"+col] / df_sub[\"rank_max_\"+col] \n",
    "    df_sub.head()\n",
    "\n",
    "    \n",
    "    df_sub[\"p_next_\"+col] = df_sub[\"p\"].shift(-1)\n",
    "    df_sub[\"p_prev_\"+col] = df_sub[\"p\"].shift(+1)\n",
    "    df_sub.head()\n",
    "    if col!=\"oof3\":\n",
    "        for c in [\"rank_\"+col,\"rank_inv_\"+col,\"rank_max_\"+col,\"rank_perc_\"+col]:\n",
    "            del df_sub[c]\n",
    "    return df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train=create_feature(train,\"oof1\")\n",
    "# train=create_feature(train,\"oof2\")\n",
    "train=create_feature(train,'oof3')\n",
    "# # train=create_feature(train,'blend')\n",
    "# train=create_feature(train,'oof4')\n",
    "# train=create_feature(train,'oof5')\n",
    "# train=create_feature(train,'oof6')\n",
    "# train=create_feature(train,'oof7')\n",
    "# train=create_feature(train,'oof8')\n",
    "# train=create_feature(train,'oof9')\n",
    "# train=create_feature(train,'oof10')\n",
    "# train=create_feature(train,'oof11')\n",
    "# train=create_feature(train,'oof12')\n",
    "# train=create_feature(train,'oof13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test=create_feature(test,'oof1')\n",
    "# test=create_feature(test,'oof2')\n",
    "test=create_feature(test,'oof3')\n",
    "# # test=create_feature(test,'blend')\n",
    "# test=create_feature(test,'oof4')\n",
    "# test=create_feature(test,'oof5')\n",
    "# test=create_feature(test,'oof6')\n",
    "# test=create_feature(test,'oof7')\n",
    "# test=create_feature(test,'oof8')\n",
    "# test=create_feature(test,'oof9')\n",
    "# test=create_feature(test,'oof10')\n",
    "# test=create_feature(test,'oof11')\n",
    "# test=create_feature(test,'oof12')\n",
    "# test=create_feature(test,'oof13')\n",
    "\n",
    "del test['p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"oof3\",]:\n",
    "    for op in [\"std\",\"skew\",\"mean\",\"max\",\"min\"]:\n",
    "        train['qid_'+col+\"_\"+op]=train.groupby(\"qid\",as_index=False)[col].transform(op)\n",
    "        \n",
    "        \n",
    "for col in ['oof3',]:\n",
    "    for op in [\"std\",\"skew\",\"mean\",\"max\",\"min\"]:\n",
    "        test['qid_'+col+\"_\"+op]=test.groupby(\"qid\",as_index=False)[col].transform(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in ['oof1',\"oof2\",\"oof3\",\"oof4\"]:\n",
    "#     for op in [\"mean\",\"std\"]:\n",
    "#         train['rid_'+col+\"_\"+op]=train.groupby(\"rid\",as_index=False)[col].transform(op)\n",
    "        \n",
    "# for col in ['oof1',\"oof2\",\"oof3\",\"oof4\"]:\n",
    "#     for op in [\"mean\",\"std\"]:\n",
    "#         test['rid_'+col+\"_\"+op]=test.groupby(\"rid\",as_index=False)[col].transform(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['rid']=(train['rid']+1)/train['id_count']\n",
    "# test['rid']=(test['rid']+1)/test['id_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21584, 40), (53757, 39))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>rid</th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>id_count</th>\n",
       "      <th>query_count</th>\n",
       "      <th>oof1</th>\n",
       "      <th>oof2</th>\n",
       "      <th>oof3</th>\n",
       "      <th>...</th>\n",
       "      <th>p1_inv_std_oof3</th>\n",
       "      <th>p1_inv_list_std</th>\n",
       "      <th>rank_perc_oof3</th>\n",
       "      <th>p_next_oof3</th>\n",
       "      <th>p_prev_oof3</th>\n",
       "      <th>qid_oof3_std</th>\n",
       "      <th>qid_oof3_skew</th>\n",
       "      <th>qid_oof3_mean</th>\n",
       "      <th>qid_oof3_max</th>\n",
       "      <th>qid_oof3_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>采荷一小是分校吧</td>\n",
       "      <td>0</td>\n",
       "      <td>杭州市采荷第一小学钱江苑校区，杭州市钱江新城实验学校。</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.993867</td>\n",
       "      <td>0.988030</td>\n",
       "      <td>0.895232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589258</td>\n",
       "      <td>0.416668</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.494750</td>\n",
       "      <td>-1.715666</td>\n",
       "      <td>0.587194</td>\n",
       "      <td>0.895232</td>\n",
       "      <td>0.016507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>采荷一小是分校吧</td>\n",
       "      <td>1</td>\n",
       "      <td>是的</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.237403</td>\n",
       "      <td>0.877518</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.016507</td>\n",
       "      <td>0.895232</td>\n",
       "      <td>0.494750</td>\n",
       "      <td>-1.715666</td>\n",
       "      <td>0.587194</td>\n",
       "      <td>0.895232</td>\n",
       "      <td>0.016507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>采荷一小是分校吧</td>\n",
       "      <td>2</td>\n",
       "      <td>这是5楼</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>0.016507</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.849844</td>\n",
       "      <td>0.494750</td>\n",
       "      <td>-1.715666</td>\n",
       "      <td>0.587194</td>\n",
       "      <td>0.895232</td>\n",
       "      <td>0.016507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>毛坯吗？</td>\n",
       "      <td>0</td>\n",
       "      <td>因为公积金贷款贷的少</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190030</td>\n",
       "      <td>0.164571</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.416678</td>\n",
       "      <td>0.016507</td>\n",
       "      <td>0.173035</td>\n",
       "      <td>2.160861</td>\n",
       "      <td>0.109312</td>\n",
       "      <td>0.416678</td>\n",
       "      <td>0.013688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>毛坯吗？</td>\n",
       "      <td>1</td>\n",
       "      <td>是呢</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.004928</td>\n",
       "      <td>0.087035</td>\n",
       "      <td>0.416678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024513</td>\n",
       "      <td>0.020015</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.029861</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.173035</td>\n",
       "      <td>2.160861</td>\n",
       "      <td>0.109312</td>\n",
       "      <td>0.416678</td>\n",
       "      <td>0.013688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid     query  rid                        reply  label  id_count  \\\n",
       "0    0  采荷一小是分校吧    0  杭州市采荷第一小学钱江苑校区，杭州市钱江新城实验学校。      1         3   \n",
       "1    0  采荷一小是分校吧    1                           是的      0         3   \n",
       "2    0  采荷一小是分校吧    2                         这是5楼      0         3   \n",
       "3    1      毛坯吗？    0                   因为公积金贷款贷的少      0         5   \n",
       "4    1      毛坯吗？    1                           是呢      0         5   \n",
       "\n",
       "   query_count      oof1      oof2      oof3  ...  p1_inv_std_oof3  \\\n",
       "0            3  0.993867  0.988030  0.895232  ...         0.589258   \n",
       "1            3  0.237403  0.877518  0.849844  ...              NaN   \n",
       "2            3  0.001440  0.003693  0.016507  ...              NaN   \n",
       "3           20  0.001333  0.003735  0.013688  ...         0.190030   \n",
       "4           20  0.004928  0.087035  0.416678  ...         0.024513   \n",
       "\n",
       "   p1_inv_list_std  rank_perc_oof3  p_next_oof3  p_prev_oof3  qid_oof3_std  \\\n",
       "0         0.416668        0.333333     0.849844          NaN      0.494750   \n",
       "1         0.000000        0.666667     0.016507     0.895232      0.494750   \n",
       "2              NaN        1.000000     0.013688     0.849844      0.494750   \n",
       "3         0.164571        0.200000     0.416678     0.016507      0.173035   \n",
       "4         0.020015        0.400000     0.029861     0.013688      0.173035   \n",
       "\n",
       "   qid_oof3_skew  qid_oof3_mean  qid_oof3_max  qid_oof3_min  \n",
       "0      -1.715666       0.587194      0.895232      0.016507  \n",
       "1      -1.715666       0.587194      0.895232      0.016507  \n",
       "2      -1.715666       0.587194      0.895232      0.016507  \n",
       "3       2.160861       0.109312      0.416678      0.013688  \n",
       "4       2.160861       0.109312      0.416678      0.013688  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [x for x in train.columns if x not in [\"id_count\",\"qid\",\"rid\",\"label\",\"reply\",\"text\",\"query\"]]\n",
    "\n",
    "label='label'\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id=train['query']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fscore(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "#     preds = 1. / (1. + np.exp(-preds))\n",
    "    return 'fscore', f1_score(labels,preds>=0.4), True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold,KFold,GroupKFold\n",
    "def run_cv_model(train, test, target, model_fn, params={}, eval_fn=None, label='model'):\n",
    "    folds=5\n",
    "    \n",
    "#     kf = KFold(n_splits=folds, random_state=1017, shuffle=False)\n",
    "#     fold_splits = kf.split(train, target)\n",
    "    kf = GroupKFold(n_splits=folds,)\n",
    "    fold_splits = kf.split(train, target,train_id)\n",
    "    cv_scores = []\n",
    "    pred_full_test = 0\n",
    "    \n",
    "    pred_train = np.zeros((train.shape[0], ))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    i = 1\n",
    "    for dev_index, val_index in fold_splits:\n",
    "        print( label + ' | FOLD ' + str(i) + '/'+str(folds))\n",
    "        if isinstance(train, pd.DataFrame):\n",
    "            dev_X, val_X = train.iloc[dev_index], train.iloc[val_index]\n",
    "            dev_y, val_y = target[dev_index], target[val_index]\n",
    "        else:\n",
    "            dev_X, val_X = train[dev_index], train[val_index]\n",
    "            dev_y, val_y = target[dev_index], target[val_index]\n",
    "        params2 = params.copy()\n",
    "        pred_val_y, pred_test_y, importances = model_fn(dev_X, dev_y, val_X, val_y, test, params2)\n",
    "        pred_full_test = pred_full_test + pred_test_y\n",
    "        pred_train[val_index] = pred_val_y\n",
    "       \n",
    "        if eval_fn is not None:\n",
    "            cv_score = eval_fn(val_y, pred_val_y>0.4)\n",
    "            cv_scores.append(cv_score)\n",
    "          \n",
    "           \n",
    "            print(label + ' cv score {}: fscore {} '.format(i, cv_score))\n",
    "            print(\"##\"*40)\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df['feature'] =train.columns.values\n",
    "        fold_importance_df['importance'] =importances\n",
    "        fold_importance_df['fold'] = i\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)        \n",
    "        i += 1\n",
    "#     print('{} cv RMSE scores : {}'.format(label, cv_scores))\n",
    "    print('{} cv mean fscore score : {}'.format(label, np.mean(cv_scores)))\n",
    "    print('{} cv std fscore score : {}'.format(label, np.std(cv_scores)))\n",
    "   \n",
    "\n",
    "    \n",
    "    pred_full_test = pred_full_test / float(folds)\n",
    "    results = {'label': label,\n",
    "               'train': pred_train, 'test': pred_full_test,\n",
    "                'cv': cv_scores, \n",
    "               'importance': feature_importance_df,\n",
    "               }\n",
    "    return results\n",
    "\n",
    "def runLGB(train_X, train_y, test_X, test_y, test_X2, params):\n",
    "#     print('Prep LGB')\n",
    "    d_train = lgb.Dataset(train_X, label=train_y)\n",
    "    d_valid = lgb.Dataset(test_X, label=test_y)\n",
    "    watchlist = [d_train, d_valid]\n",
    "#     print('Train LGB')\n",
    "    num_rounds = params.pop('num_rounds')\n",
    "    verbose_eval = params.pop('verbose_eval')\n",
    "    early_stop = None\n",
    "    if params.get('early_stop'):\n",
    "        early_stop = params.pop('early_stop')\n",
    "    model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=num_rounds,\n",
    "                      valid_sets=watchlist,\n",
    "#                       fobj=softkappaObj,\n",
    "                      verbose_eval=verbose_eval,\n",
    "#                       feval=fscore,\n",
    "                      early_stopping_rounds=early_stop)\n",
    "    print('Predict 1/2')\n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "   \n",
    "    print('Predict 2/2')\n",
    "    pred_test_y2 = model.predict(test_X2, num_iteration=model.best_iteration)\n",
    "    \n",
    "   \n",
    "    return pred_test_y,pred_test_y2, model.feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB | FOLD 1/5\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's binary_logloss: 0.205018\tvalid_1's binary_logloss: 0.229253\n",
      "[400]\ttraining's binary_logloss: 0.162833\tvalid_1's binary_logloss: 0.207967\n",
      "[600]\ttraining's binary_logloss: 0.141338\tvalid_1's binary_logloss: 0.207617\n",
      "Early stopping, best iteration is:\n",
      "[505]\ttraining's binary_logloss: 0.150486\tvalid_1's binary_logloss: 0.207155\n",
      "Predict 1/2\n",
      "Predict 2/2\n",
      "LGB cv score 1: fscore 0.8456712672521958 \n",
      "################################################################################\n",
      "LGB | FOLD 2/5\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's binary_logloss: 0.208106\tvalid_1's binary_logloss: 0.219509\n",
      "[400]\ttraining's binary_logloss: 0.16522\tvalid_1's binary_logloss: 0.199169\n",
      "[600]\ttraining's binary_logloss: 0.1439\tvalid_1's binary_logloss: 0.198337\n",
      "Early stopping, best iteration is:\n",
      "[484]\ttraining's binary_logloss: 0.155297\tvalid_1's binary_logloss: 0.198242\n",
      "Predict 1/2\n",
      "Predict 2/2\n",
      "LGB cv score 2: fscore 0.8282926829268292 \n",
      "################################################################################\n",
      "LGB | FOLD 3/5\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's binary_logloss: 0.205196\tvalid_1's binary_logloss: 0.23018\n",
      "[400]\ttraining's binary_logloss: 0.16265\tvalid_1's binary_logloss: 0.209104\n",
      "[600]\ttraining's binary_logloss: 0.141139\tvalid_1's binary_logloss: 0.208331\n",
      "[800]\ttraining's binary_logloss: 0.125467\tvalid_1's binary_logloss: 0.208405\n",
      "Early stopping, best iteration is:\n",
      "[693]\ttraining's binary_logloss: 0.133466\tvalid_1's binary_logloss: 0.207973\n",
      "Predict 1/2\n",
      "Predict 2/2\n",
      "LGB cv score 3: fscore 0.829675153643547 \n",
      "################################################################################\n",
      "LGB | FOLD 4/5\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's binary_logloss: 0.203794\tvalid_1's binary_logloss: 0.234598\n",
      "[400]\ttraining's binary_logloss: 0.160977\tvalid_1's binary_logloss: 0.21658\n",
      "[600]\ttraining's binary_logloss: 0.13946\tvalid_1's binary_logloss: 0.217023\n",
      "Early stopping, best iteration is:\n",
      "[458]\ttraining's binary_logloss: 0.15373\tvalid_1's binary_logloss: 0.216138\n",
      "Predict 1/2\n",
      "Predict 2/2\n",
      "LGB cv score 4: fscore 0.8210240144993203 \n",
      "################################################################################\n",
      "LGB | FOLD 5/5\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's binary_logloss: 0.206353\tvalid_1's binary_logloss: 0.230951\n",
      "[400]\ttraining's binary_logloss: 0.163964\tvalid_1's binary_logloss: 0.208685\n",
      "[600]\ttraining's binary_logloss: 0.142266\tvalid_1's binary_logloss: 0.206742\n",
      "[800]\ttraining's binary_logloss: 0.12635\tvalid_1's binary_logloss: 0.206513\n",
      "[1000]\ttraining's binary_logloss: 0.113134\tvalid_1's binary_logloss: 0.206505\n",
      "Early stopping, best iteration is:\n",
      "[862]\ttraining's binary_logloss: 0.12199\tvalid_1's binary_logloss: 0.206264\n",
      "Predict 1/2\n",
      "Predict 2/2\n",
      "LGB cv score 5: fscore 0.8255002326663565 \n",
      "################################################################################\n",
      "LGB cv mean fscore score : 0.8300326701976498\n",
      "LGB cv std fscore score : 0.008359664575683044\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "            'objective': 'binary', \n",
    "          'boosting': 'gbdt',\n",
    "          'metric': 'binary_logloss',\n",
    "          'num_leaves': 32,\n",
    "          'learning_rate': 0.01,\n",
    "          'bagging_fraction': 0.7,\n",
    "            \"bagging_freq\":3,\n",
    "           'feature_fraction': 0.4,\n",
    "          'verbosity': -1,\n",
    "          \"data_random_seed\":17,\n",
    "          \"random_state\":1017,\n",
    "            'num_rounds': 6000,\n",
    "    'num_threads':2,\n",
    "    'verbose_eval': 200,\n",
    "    'early_stop':200,\n",
    "#          'device': 'gpu',\n",
    "#     'gpu_platform_id': 0,\n",
    "#     'gpu_device_id': 0,\n",
    "}\n",
    "results = run_cv_model(train[features], test[features], train[label], runLGB, params, f1_score , 'LGB')\n",
    "lgb_train=[r for r in results['train']]\n",
    "lgb_test=[r for r in results['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zqs/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oof4</td>\n",
       "      <td>868.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oof5</td>\n",
       "      <td>856.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oof17</td>\n",
       "      <td>822.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oof2</td>\n",
       "      <td>815.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oof11</td>\n",
       "      <td>770.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>oof3</td>\n",
       "      <td>737.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oof14</td>\n",
       "      <td>707.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>oof12</td>\n",
       "      <td>706.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>oof10</td>\n",
       "      <td>702.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>oof13</td>\n",
       "      <td>687.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>oof1</td>\n",
       "      <td>684.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>oof7</td>\n",
       "      <td>683.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>oof6</td>\n",
       "      <td>674.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>diff_mean_oof3</td>\n",
       "      <td>662.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>qid_oof3_skew</td>\n",
       "      <td>646.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>oof8</td>\n",
       "      <td>644.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>p1_inv_oof3</td>\n",
       "      <td>611.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>p_prev_oof3</td>\n",
       "      <td>603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>qid_oof3_min</td>\n",
       "      <td>587.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>qid_oof3_std</td>\n",
       "      <td>570.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>p_next_oof3</td>\n",
       "      <td>524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>p1_oof3</td>\n",
       "      <td>493.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>p1_inv_std_oof3</td>\n",
       "      <td>492.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>qid_oof3_mean</td>\n",
       "      <td>479.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>qid_oof3_max</td>\n",
       "      <td>455.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>p1_inv_list_std</td>\n",
       "      <td>425.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>diff_std_oof3</td>\n",
       "      <td>402.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>query_count</td>\n",
       "      <td>347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>p1_std_oof3</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>p1_list_std</td>\n",
       "      <td>261.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rank_perc_oof3</td>\n",
       "      <td>134.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rank_inv_oof3</td>\n",
       "      <td>105.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>rank_max_oof3</td>\n",
       "      <td>65.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>rank_oof3</td>\n",
       "      <td>42.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  importance\n",
       "0              oof4       868.6\n",
       "1              oof5       856.0\n",
       "2             oof17       822.8\n",
       "3              oof2       815.4\n",
       "4             oof11       770.4\n",
       "5              oof3       737.0\n",
       "6             oof14       707.6\n",
       "7             oof12       706.6\n",
       "8             oof10       702.0\n",
       "9             oof13       687.0\n",
       "10             oof1       684.8\n",
       "11             oof7       683.6\n",
       "12             oof6       674.6\n",
       "13   diff_mean_oof3       662.2\n",
       "14    qid_oof3_skew       646.6\n",
       "15             oof8       644.0\n",
       "16      p1_inv_oof3       611.2\n",
       "17      p_prev_oof3       603.0\n",
       "18     qid_oof3_min       587.8\n",
       "19     qid_oof3_std       570.8\n",
       "20      p_next_oof3       524.0\n",
       "21          p1_oof3       493.6\n",
       "22  p1_inv_std_oof3       492.8\n",
       "23    qid_oof3_mean       479.8\n",
       "24     qid_oof3_max       455.8\n",
       "25  p1_inv_list_std       425.4\n",
       "26    diff_std_oof3       402.6\n",
       "27      query_count       347.0\n",
       "28      p1_std_oof3       340.0\n",
       "29      p1_list_std       261.4\n",
       "30   rank_perc_oof3       134.2\n",
       "31    rank_inv_oof3       105.8\n",
       "32    rank_max_oof3        65.6\n",
       "33        rank_oof3        42.4"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imports = results['importance'].groupby('feature')['feature', 'importance'].mean().reset_index()\n",
    "imp=imports.sort_values('importance', ascending=False)\n",
    "imp.index=range(len(imp))\n",
    "imp.iloc[:63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = imp.feature.values[:59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin: 0.8240530303030303\n",
      "best 0.8308113035551504\n",
      "thres 0.419\n"
     ]
    }
   ],
   "source": [
    "best_score, best_t = search_f1(train['label'].values,np.array(lgb_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import partial\n",
    "# import scipy as sp\n",
    "# class OptimizedRounder(object):\n",
    "#     \"\"\"\n",
    "#     An optimizer for rounding thresholds\n",
    "#     to maximize F1 (Macro) score\n",
    "#     # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n",
    "#     \"\"\"\n",
    "#     def __init__(self):\n",
    "#         self.coef_ = 0\n",
    "\n",
    "#     def _f1_loss(self, coef, X, y):\n",
    "#         \"\"\"\n",
    "#         Get loss according to\n",
    "#         using current coefficients\n",
    "        \n",
    "#         :param coef: A list of coefficients that will be used for rounding\n",
    "#         :param X: The raw predictions\n",
    "#         :param y: The ground truth labels\n",
    "#         \"\"\"\n",
    "#         X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1])\n",
    "\n",
    "#         return -f1_score(y, X_p)\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         \"\"\"\n",
    "#         Optimize rounding thresholds\n",
    "        \n",
    "#         :param X: The raw predictions\n",
    "#         :param y: The ground truth labels\n",
    "#         \"\"\"\n",
    "#         loss_partial = partial(self._f1_loss, X=X, y=y)\n",
    "#         initial_coef = [0.5]\n",
    "#         self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n",
    "\n",
    "#     def predict(self, X, coef):\n",
    "#         \"\"\"\n",
    "#         Make predictions with specified thresholds\n",
    "        \n",
    "#         :param X: The raw predictions\n",
    "#         :param coef: A list of coefficients that will be used for rounding\n",
    "#         \"\"\"\n",
    "#         return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1])\n",
    "\n",
    "\n",
    "#     def coefficients(self):\n",
    "#         \"\"\"\n",
    "#         Return the optimized coefficients\n",
    "#         \"\"\"\n",
    "#         return self.coef_['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optR = OptimizedRounder()\n",
    "\n",
    "# optR.fit(np.array(lgb_train), train['label'])\n",
    "# coefficients = optR.coefficients()\n",
    "# print(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zqs/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/zqs/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "sub = test[['qid','rid']]\n",
    "sub['pred'] = lgb_test\n",
    "sub['label'] = sub['pred'].map(lambda x:1 if x>= best_t else 0)\n",
    "sub[['qid','rid','label']].to_csv(\"./submit/chizhu_final1.csv\",sep=\"\\t\",index=None,header=None)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = sub1.copy()\n",
    "# sub['label'] =sub1['pred']*0.2+sub2['pred']*0.25+sub3['pred']*0.35+sub4['pred']*0.2\n",
    "# sub['label'] = sub['label'].map(lambda x:1 if x>= best_t else 0)\n",
    "# sub[[\"qid\",'rid','label']].to_csv(\"./submit/submit_blend_{}.csv\".format(best_score),sep=\"\\t\",index=None,header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>rid</th>\n",
       "      <th>pred</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53752</th>\n",
       "      <td>13998</td>\n",
       "      <td>3</td>\n",
       "      <td>0.046517</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53753</th>\n",
       "      <td>13998</td>\n",
       "      <td>4</td>\n",
       "      <td>0.010164</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53754</th>\n",
       "      <td>13999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.071518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53755</th>\n",
       "      <td>13999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53756</th>\n",
       "      <td>13999</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53757 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         qid  rid      pred  label\n",
       "0          0    0  0.046048      0\n",
       "1          0    1  0.006374      0\n",
       "2          0    2  0.005464      0\n",
       "3          0    3  0.005118      0\n",
       "4          0    4  0.004960      0\n",
       "...      ...  ...       ...    ...\n",
       "53752  13998    3  0.046517      0\n",
       "53753  13998    4  0.010164      0\n",
       "53754  13999    0  0.071518      0\n",
       "53755  13999    1  0.059867      0\n",
       "53756  13999    2  0.011006      0\n",
       "\n",
       "[53757 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    40884\n",
       "1    12873\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.read_csv(\"./submit/chenhao.csv\",sep=\"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    40396\n",
       "1    13361\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.read_csv(\"./submit/8067.csv\",sep=\"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    40289\n",
       "1    13468\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
